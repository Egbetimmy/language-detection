{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144381c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\BUYPC\n",
      "[nltk_data]     COMPUTERS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\BUYPC\n",
      "[nltk_data]     COMPUTERS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\BUYPC\n",
      "[nltk_data]     COMPUTERS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords, wordnet \n",
    "from wordcloud import WordCloud\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import (\n",
    "    Markdown as md,\n",
    "    Latex,\n",
    "    HTML,\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# set plot style\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6919b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_set.csv\")\n",
    "df_test = pd.read_csv(\"test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea683dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635e11d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "920b0f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_case(word):\n",
    "    return word.str.lower()\n",
    "df_train['nt_text'] = change_case(df_train['text'])\n",
    "df_test['nt_text'] = change_case(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de0c547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopword(tokens):\n",
    "    # Remove stop words from the token list\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    return filtered_tokens\n",
    "df_train['sw_text'] = remove_stopword(df_train['nt_text'])\n",
    "df_test['sw_text'] = remove_stopword(df_test['nt_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5e6c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \\n and \\t with \" \"\n",
    "def remove_newlines(word):\n",
    "    # Replace newlines and tabs with spaces\n",
    "    word = re.sub(r\"[\\n\\t]\", \" \", word)\n",
    "    return word\n",
    "# Apply newline removal to the 'text' column\n",
    "df_train['nl_text'] = df_train['sw_text'].apply(remove_newlines)\n",
    "df_test['nl_text'] = df_test['sw_text'].apply(remove_newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abfc2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    alphabet = string.ascii_lowercase\n",
    "    return ''.join([x for x in text if x in alphabet + \" \"])\n",
    "df_train['no_punc'] = df_train['nl_text'].apply(remove_punctuation)\n",
    "df_test['no_punc'] = df_test['nl_text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b36d41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>nt_text</th>\n",
       "      <th>sw_message</th>\n",
       "      <th>sw_text</th>\n",
       "      <th>nl_text</th>\n",
       "      <th>no_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>[u, g, q, e, k,  , w, e, n, z,  , l, u, n, g, ...</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>[h,  ,  , k, u, b,  , n, b, u, l, u, k,  , b, ...</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>[h, e,  , p, r, v, n, c, e,  , f,  , k, w, z, ...</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulunatal department of tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>[ , n, e, e, f,  , g, r, e,  ,  , b,  , f, l, ...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefata gore o ba file dilo ka moka te le d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>[k, h, h, n,  ,  , n, n, g, n,  ,  , b, e, u, ...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2     eng  the province of kwazulu-natal department of tr...   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  [u, g, q, e, k,  , w, e, n, z,  , l, u, n, g, ...   \n",
       "1  [h,  ,  , k, u, b,  , n, b, u, l, u, k,  , b, ...   \n",
       "2  [h, e,  , p, r, v, n, c, e,  , f,  , k, w, z, ...   \n",
       "3  [ , n, e, e, f,  , g, r, e,  ,  , b,  , f, l, ...   \n",
       "4  [k, h, h, n,  ,  , n, n, g, n,  ,  , b, e, u, ...   \n",
       "\n",
       "                                             nt_text  \\\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu-natal department of tr...   \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                          sw_message  \\\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu-natal department of tr...   \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                             sw_text  \\\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu-natal department of tr...   \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                             nl_text  \\\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu-natal department of tr...   \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                             no_punc  \n",
       "0  umgaqosiseko wenza amalungiselelo kumaziko axh...  \n",
       "1  idha iya kuba nobulumko bokubeka umsebenzi nap...  \n",
       "2  the province of kwazulunatal department of tra...  \n",
       "3  o netefata gore o ba file dilo ka moka te le d...  \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5f448b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _analyzer (x):\n",
    "    \"\"\"\n",
    "    Function combines all the cleaning operations\n",
    "    \"\"\"\n",
    "    x = remove_punctuation(x)\n",
    "    x = normalize_text(x)\n",
    "    x = x.apply(remove_newlines)\n",
    "    x = remove_stopword(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd0b7af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>nt_text</th>\n",
       "      <th>sw_message</th>\n",
       "      <th>sw_text</th>\n",
       "      <th>nl_text</th>\n",
       "      <th>no_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>[u, g, q, e, k,  , w, e, n, z,  , l, u, n, g, ...</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>[h,  ,  , k, u, b,  , n, b, u, l, u, k,  , b, ...</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>[h, e,  , p, r, v, n, c, e,  , f,  , k, w, z, ...</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulunatal department of tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>[ , n, e, e, f,  , g, r, e,  ,  , b,  , f, l, ...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefata gore o ba file dilo ka moka te le d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>[k, h, h, n,  ,  , n, n, g, n,  ,  , b, e, u, ...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2     eng  the province of kwazulu-natal department of tr...   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  [u, g, q, e, k,  , w, e, n, z,  , l, u, n, g, ...   \n",
       "1  [h,  ,  , k, u, b,  , n, b, u, l, u, k,  , b, ...   \n",
       "2  [h, e,  , p, r, v, n, c, e,  , f,  , k, w, z, ...   \n",
       "3  [ , n, e, e, f,  , g, r, e,  ,  , b,  , f, l, ...   \n",
       "4  [k, h, h, n,  ,  , n, n, g, n,  ,  , b, e, u, ...   \n",
       "\n",
       "                                             nt_text  \\\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu-natal department of tr...   \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                          sw_message  \\\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu-natal department of tr...   \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                             sw_text  \\\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu-natal department of tr...   \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                             nl_text  \\\n",
       "0  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu-natal department of tr...   \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                             no_punc  \n",
       "0  umgaqosiseko wenza amalungiselelo kumaziko axh...  \n",
       "1  idha iya kuba nobulumko bokubeka umsebenzi nap...  \n",
       "2  the province of kwazulunatal department of tra...  \n",
       "3  o netefata gore o ba file dilo ka moka te le d...  \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaa27059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting  X (indepedent) and Y (target/dependent) variables\n",
    "X = df_train['no_punc']\n",
    "y = df_train['lang_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8afde452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y, stratify=y,\n",
    "                                                       test_size =0.4, \n",
    "                                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e3e9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d42cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = [LogisticRegression(random_state =42 , max_iter=5000) , \n",
    "       MultinomialNB(), LinearSVC(random_state=42), \n",
    "       SGDClassifier(random_state=42), RidgeClassifier(random_state=42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffba0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a2f15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_assessment(algorithms, X_train, y_train, X_test, y_test):\n",
    "    model_stats = {}\n",
    "\n",
    "    for clf in algorithms:\n",
    "        model = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', max_df=0.9, ngram_range=(1, 5), analyzer='char')),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train, y_train)  # Training\n",
    "        model_pred = model.predict(X_test)  # Testing\n",
    "\n",
    "        model_name = clf.__class__.__name__\n",
    "        f1_macro = metrics.f1_score(y_test, model_pred, average='macro')\n",
    "        f1_micro = metrics.f1_score(y_test, model_pred, average='micro')\n",
    "        f1_weighted = metrics.f1_score(y_test, model_pred, average='weighted')\n",
    "\n",
    "        model_stats[model_name] = {\n",
    "            'F1-Macro': f1_macro,\n",
    "            'F1-Accuracy': f1_micro,\n",
    "            'F1-Weighted': f1_weighted\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(model_stats, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ced747dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.999318</td>\n",
       "      <td>0.999318</td>\n",
       "      <td>0.999318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.998939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.998182</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>0.998182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1-Macro  F1-Accuracy  F1-Weighted\n",
       "MultinomialNB       0.999318     0.999318     0.999318\n",
       "RidgeClassifier     0.999167     0.999167     0.999167\n",
       "LinearSVC           0.999091     0.999091     0.999091\n",
       "SGDClassifier       0.998939     0.998939     0.998939\n",
       "LogisticRegression  0.998182     0.998182     0.998182"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = _performace_assesment(alg , X_train , X_test , y_train , y_test)\n",
    "performance.to_csv('performance.csv')\n",
    "dataframe = pd.read_csv('performance.csv', index_col = 0)\n",
    "dataframe.sort_values('F1-Weighted', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08ff629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_tuning(algorithms, X_train, y_train):\n",
    "    best_params = {}\n",
    "\n",
    "    for clf in algorithms:\n",
    "        model = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', max_df=0.9, ngram_range=(1, 5), analyzer='char')),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train, y_train)  # Training\n",
    "\n",
    "        params = model.get_params()\n",
    "        model_name = clf.__class__.__name__\n",
    "        model_params = {}\n",
    "\n",
    "        for key in params:\n",
    "            if key.startswith(\"clf__\"):\n",
    "                param_name = key.split('__', 1)[1]  # Extract parameter name\n",
    "                model_params[param_name] = params[key]\n",
    "\n",
    "        best_params[model_name] = model_params\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0aa2ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_params = _param_tuning(alg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4376adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'model': LogisticRegression(max_iter=5000, random_state=42),\n",
       "  'C': 1.0,\n",
       "  'class_weight': None,\n",
       "  'dual': False,\n",
       "  'fit_intercept': True,\n",
       "  'intercept_scaling': 1,\n",
       "  'l1_ratio': None,\n",
       "  'max_iter': 5000,\n",
       "  'multi_class': 'auto',\n",
       "  'n_jobs': None,\n",
       "  'penalty': 'l2',\n",
       "  'random_state': 42,\n",
       "  'solver': 'lbfgs',\n",
       "  'tol': 0.0001,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False},\n",
       " 'MultinomialNB': {'model': MultinomialNB(),\n",
       "  'alpha': 1.0,\n",
       "  'class_prior': None,\n",
       "  'fit_prior': True,\n",
       "  'force_alpha': 'warn'},\n",
       " 'LinearSVC': {'model': LinearSVC(random_state=42),\n",
       "  'C': 1.0,\n",
       "  'class_weight': None,\n",
       "  'dual': True,\n",
       "  'fit_intercept': True,\n",
       "  'intercept_scaling': 1,\n",
       "  'loss': 'squared_hinge',\n",
       "  'max_iter': 1000,\n",
       "  'multi_class': 'ovr',\n",
       "  'penalty': 'l2',\n",
       "  'random_state': 42,\n",
       "  'tol': 0.0001,\n",
       "  'verbose': 0},\n",
       " 'SGDClassifier': {'model': SGDClassifier(random_state=42),\n",
       "  'alpha': 0.0001,\n",
       "  'average': False,\n",
       "  'class_weight': None,\n",
       "  'early_stopping': False,\n",
       "  'epsilon': 0.1,\n",
       "  'eta0': 0.0,\n",
       "  'fit_intercept': True,\n",
       "  'l1_ratio': 0.15,\n",
       "  'learning_rate': 'optimal',\n",
       "  'loss': 'hinge',\n",
       "  'max_iter': 1000,\n",
       "  'n_iter_no_change': 5,\n",
       "  'n_jobs': None,\n",
       "  'penalty': 'l2',\n",
       "  'power_t': 0.5,\n",
       "  'random_state': 42,\n",
       "  'shuffle': True,\n",
       "  'tol': 0.001,\n",
       "  'validation_fraction': 0.1,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False},\n",
       " 'RidgeClassifier': {'model': RidgeClassifier(random_state=42),\n",
       "  'alpha': 1.0,\n",
       "  'class_weight': None,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'positive': False,\n",
       "  'random_state': 42,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.0001}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f40763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model1 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e8d2a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Vectorize = TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(1, 5), analyzer= 'char')\n",
    "X_train = Vectorize.fit_transform(X_train)\n",
    "X_test = Vectorize.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "182b1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True,\n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa795940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': MultinomialNB(),\n",
       " 'alpha': 1.0,\n",
       " 'class_prior': None,\n",
       " 'fit_prior': True,\n",
       " 'force_alpha': 'warn'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[alg[1].__class__.__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "edf53ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = list(np.linspace(0.1,0.02,4))\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid_search = GridSearchCV(estimator= model1,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1_weighted',\n",
    "                           cv=stratified_kfold,\n",
    "                           error_score=0,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0a3fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "prediction = grid_search.predict(X_test)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45a59140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.9996464641593393\n",
      "Test score: 0.9995455174533855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Cross-validation score: {cv_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "grid_search.best_params_    \n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d285a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': RidgeClassifier(random_state=42),\n",
       " 'alpha': 1.0,\n",
       " 'class_weight': None,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'positive': False,\n",
       " 'random_state': 42,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.0001}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "model2 = RidgeClassifier()\n",
    "best_params[alg[4].__class__.__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ba94545",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = list(np.linspace(0.15,0.4, 5))\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid_search = GridSearchCV(estimator= model2,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1_weighted',\n",
    "                           cv=stratified_kfold,\n",
    "                           error_score=0,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "737ecf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "prediction = grid_search.predict(X_test)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2e19de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.999545452790985\n",
      "Test score: 0.9993181815945916\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier(alpha=0.15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=0.15)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier(alpha=0.15)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Cross-validation score: {cv_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "grid_search.best_params_    \n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff119664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6fe4408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X, y,  stratify=y, test_size=0.4, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b95f9c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BUYPC COMPUTERS\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(2, 6), analyzer= 'char')\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70b492f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiNB1 = MultinomialNB(alpha=0.1)\n",
    "multiNB2 = MultinomialNB(alpha=0.1)\n",
    "\n",
    "estimators = [('multiNB1', multiNB1), ('multiNB2', multiNB2)]\n",
    "final_est = RidgeClassifier(alpha=0.2125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c68d3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_NB2 = StackingClassifier(estimators = estimators,\n",
    "                           final_estimator = final_est,\n",
    "                           passthrough = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f9be2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;multiNB1&#x27;, MultinomialNB(alpha=0.1)),\n",
       "                               (&#x27;multiNB2&#x27;, MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=RidgeClassifier(alpha=0.2125),\n",
       "                   passthrough=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;multiNB1&#x27;, MultinomialNB(alpha=0.1)),\n",
       "                               (&#x27;multiNB2&#x27;, MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=RidgeClassifier(alpha=0.2125),\n",
       "                   passthrough=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>multiNB1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>multiNB2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=0.2125)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('multiNB1', MultinomialNB(alpha=0.1)),\n",
       "                               ('multiNB2', MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=RidgeClassifier(alpha=0.2125),\n",
       "                   passthrough=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_NB2.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b36223e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stacking_NB2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d8c589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StackingClassifier</th>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1-Macro  F1-Accuracy  F1-Weighted\n",
       "StackingClassifier  0.999773     0.999773     0.999773"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = {}\n",
    "model_stats[stacking_NB2.__class__.__name__] = {\n",
    "        'F1-Macro':metrics.f1_score(y_test, pred, average='macro'),\n",
    "        'F1-Accuracy':metrics.f1_score(y_test, pred, average='micro'),\n",
    "        'F1-Weighted':metrics.f1_score(y_test, pred, average='weighted')}\n",
    "pd.DataFrame.from_dict(model_stats, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bc0c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(3,7), analyzer= 'char')\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, stratify=y,test_size=0.05, random_state =1)\n",
    "X_train = count_vec.fit_transform(X_train)\n",
    "X_test = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6be52ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiNB1 = MultinomialNB(alpha=0.1)\n",
    "multiNB2 = MultinomialNB(alpha=0.1)\n",
    "multiNB3 = MultinomialNB(alpha=0.1)\n",
    "\n",
    "estimators = [('multiNB1', multiNB1), ('multiNB2', multiNB2), ('multiNB3', multiNB3)]\n",
    "final_est = RidgeClassifier(alpha=0.2125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dda73829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>nso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index lang_id\n",
       "0         1     tsn\n",
       "1         2     nbl\n",
       "2         3     ven\n",
       "3         4     ssw\n",
       "4         5     afr\n",
       "...     ...     ...\n",
       "5677   5678     eng\n",
       "5678   5679     nso\n",
       "5679   5680     sot\n",
       "5680   5681     sot\n",
       "5681   5682     nbl\n",
       "\n",
       "[5682 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_test['no_punc']\n",
    "Vectorize = vect.transform(X)\n",
    "df_test['lang_id'] = stacking_NB2.predict(Vectorize)\n",
    "submission = df_test[['index', 'lang_id']]\n",
    "submission.to_csv('Submission.csv',index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957f6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
